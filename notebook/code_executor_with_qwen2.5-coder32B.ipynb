{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822cffe4-2179-4086-a04f-761f132fa24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\agents\\code_executor\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from llm_pyexecutor import LLMPythonCodeExecutor\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../.env\")\n",
    "MODEL = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
    "client = InferenceClient(api_key=os.getenv(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ab70b6-1681-4e15-b50a-4d58c79c40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt: str):\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": prompt }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL, \n",
    "        messages=messages, \n",
    "        temperature=0.5,\n",
    "        max_tokens=2048,\n",
    "        top_p=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c910309-6c4d-4ef2-8537-4e00a6f129f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a linear regression model involves several steps, from data preparation to model evaluation. Here's a step-by-step guide to help you through the process:\n",
      "\n",
      "### Step 1: Understand the Problem\n",
      "- **Define the Objective**: Clearly define what you want to predict. For example, predicting house prices based on features like size, number of bedrooms, etc.\n",
      "- **Identify the Type of Problem**: Ensure that the problem is suitable for linear regression. Linear regression is used for predicting a continuous target variable.\n",
      "\n",
      "### Step 2: Collect and Prepare the Data\n",
      "- **Collect Data**: Gather the dataset that includes both the features (independent variables) and the target (dependent variable).\n",
      "- **Explore the Data**: Perform exploratory data analysis (EDA) to understand the data distribution, identify missing values, and detect outliers.\n",
      "- **Clean the Data**: Handle missing values, remove duplicates, and correct any inconsistencies.\n",
      "- **Feature Selection/Engineering**: Select relevant features and create new features if necessary. This step can involve domain knowledge and statistical tests.\n",
      "- **Normalize/Standardize the Data**: Scale the features to ensure they contribute equally to the distance calculations in the model. This is especially important for algorithms sensitive to the scale of the data.\n",
      "\n",
      "### Step 3: Split the Data\n",
      "- **Train-Test Split**: Divide the dataset into training and testing sets. A common split is 80% for training and 20% for testing. This helps in evaluating the model's performance on unseen data.\n",
      "\n",
      "### Step 4: Choose the Model\n",
      "- **Select the Algorithm**: For linear regression, you will use the linear regression algorithm. In Python, you can use libraries like `scikit-learn` to implement linear regression.\n",
      "\n",
      "### Step 5: Train the Model\n",
      "- **Fit the Model**: Use the training data to fit the linear regression model. This involves finding the best-fit line that minimizes the error between the predicted and actual values.\n",
      "  \n",
      "  ```python\n",
      "  from sklearn.linear_model import LinearRegression\n",
      "  from sklearn.model_selection import train_test_split\n",
      "  import pandas as pd\n",
      "\n",
      "  # Load your dataset\n",
      "  data = pd.read_csv('your_dataset.csv')\n",
      "\n",
      "  # Define features and target\n",
      "  X = data[['feature1', 'feature2', 'feature3']]  # Replace with your feature columns\n",
      "  y = data['target']  # Replace with your target column\n",
      "\n",
      "  # Split the data\n",
      "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "  # Initialize the model\n",
      "  model = LinearRegression()\n",
      "\n",
      "  # Fit the model\n",
      "  model.fit(X_train, y_train)\n",
      "  ```\n",
      "\n",
      "### Step 6: Evaluate the Model\n",
      "- **Make Predictions**: Use the trained model to make predictions on the test set.\n",
      "- **Evaluate Performance**: Assess the model's performance using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared.\n",
      "\n",
      "  ```python\n",
      "  from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
      "\n",
      "  # Make predictions\n",
      "  y_pred = model.predict(X_test)\n",
      "\n",
      "  # Evaluate the model\n",
      "  mae = mean_absolute_error(y_test, y_pred)\n",
      "  mse = mean_squared_error(y_test, y_pred)\n",
      "  r2 = r2_score(y_test, y_pred)\n",
      "\n",
      "  print(f'MAE: {mae}')\n",
      "  print(f'MSE: {mse}')\n",
      "  print(f'R-squared: {r2}')\n",
      "  ```\n",
      "\n",
      "### Step 7: Improve the Model\n",
      "- **Feature Selection**: Try different combinations of features to see if performance improves.\n",
      "- **Regularization**: Apply techniques like Lasso or Ridge regression to prevent overfitting.\n",
      "- **Hyperparameter Tuning**: Although linear regression has few hyperparameters, you can still tune them if needed.\n",
      "\n",
      "### Step 8: Deploy the Model\n",
      "- **Save the Model**: Once satisfied with the model's performance, save it for future use.\n",
      "- **Deploy the Model**: Integrate the model into a production environment where it can make predictions on new data.\n",
      "\n",
      "By following these steps, you can effectively train a linear regression model to solve your problem.\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"how to train linear regression model\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1d5017-b075-45d9-82b8-4a0aabfac1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To calculate the dot product between two matrices in Python, you can use the `numpy` library, which provides a convenient function called `dot` for this purpose. Here\\'s a step-by-step guide on how to do it:\\n\\n1. Install `numpy` if you haven\\'t already. You can install it using pip:\\n   ```bash\\n   pip install numpy\\n   ```\\n\\n2. Use the `numpy.dot` function to calculate the dot product of two matrices.\\n\\nHere\\'s an example:\\n\\n```python\\nimport numpy as np\\n\\n# Define two matrices\\nmatrix_a = np.array([[1, 2, 3],\\n                     [4, 5, 6]])\\n\\nmatrix_b = np.array([[7, 8],\\n                     [9, 10],\\n                     [11, 12]])\\n\\n# Calculate the dot product\\ndot_product = np.dot(matrix_a, matrix_b)\\n\\n# Alternatively, you can use the @ operator for matrix multiplication\\n# dot_product = matrix_a @ matrix_b\\n\\nprint(\"Dot Product:\")\\nprint(dot_product)\\n```\\n\\nIn this example, `matrix_a` is a 2x3 matrix and `matrix_b` is a 3x2 matrix. The dot product of these two matrices will result in a 2x2 matrix.\\n\\nOutput:\\n```\\nDot Product:\\n[[ 58  64]\\n [139 154]]\\n```\\n\\nMake sure that the number of columns in the first matrix (`matrix_a`) is equal to the number of rows in the second matrix (`matrix_b`) for the dot product to be defined.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = llm(\"calculate dot product between two metrices in python\")\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56652dc2-b0ef-422b-9737-cd6e14267c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-07 14:35:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mstarting code execution tool\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCreating Executor Virtual Environment\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFound Existing Environment\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLLM Generated Text: \n",
      "To calculate the dot product between two matrices in Python, you can use the `numpy` library, which provides a convenient function called `dot` for this purpose. Here's a step-by-step guide on how to do it:\n",
      "\n",
      "1. Install `numpy` if you haven't already. You can install it using pip:\n",
      "   ```bash\n",
      "   pip install numpy\n",
      "   ```\n",
      "\n",
      "2. Use the `numpy.dot` function to calculate the dot product of two matrices.\n",
      "\n",
      "Here's an example:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "# Define two matrices\n",
      "matrix_a = np.array([[1, 2, 3],\n",
      "                     [4, 5, 6]])\n",
      "\n",
      "matrix_b = np.array([[7, 8],\n",
      "                     [9, 10],\n",
      "                     [11, 12]])\n",
      "\n",
      "# Calculate the dot product\n",
      "dot_product = np.dot(matrix_a, matrix_b)\n",
      "\n",
      "# Alternatively, you can use the @ operator for matrix multiplication\n",
      "# dot_product = matrix_a @ matrix_b\n",
      "\n",
      "print(\"Dot Product:\")\n",
      "print(dot_product)\n",
      "```\n",
      "\n",
      "In this example, `matrix_a` is a 2x3 matrix and `matrix_b` is a 3x2 matrix. The dot product of these two matrices will result in a 2x2 matrix.\n",
      "\n",
      "Output:\n",
      "```\n",
      "Dot Product:\n",
      "[[ 58  64]\n",
      " [139 154]]\n",
      "```\n",
      "\n",
      "Make sure that the number of columns in the first matrix (`matrix_a`) is equal to the number of rows in the second matrix (`matrix_b`) for the dot product to be defined.\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mSearching for Packages to install from text\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mExtracted Python Code: \n",
      "import numpy as np\n",
      "\n",
      "# Define two matrices\n",
      "matrix_a = np.array([[1, 2, 3],\n",
      "                     [4, 5, 6]])\n",
      "matrix_b = np.array([[7, 8],\n",
      "                     [9, 10],\n",
      "                     [11, 12]])\n",
      "# Calculate the dot product\n",
      "dot_product = np.dot(matrix_a, matrix_b)\n",
      "# Alternatively, you can use the @ operator for matrix multiplication\n",
      "# dot_product = matrix_a @ matrix_b\n",
      "print(\"Dot Product:\")\n",
      "print(dot_product)\n",
      "\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mPython Code Dependencies: \n",
      "[{'module': 'numpy', 'name': 'numpy', 'alias': 'np'}]\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCheck if packages are installed\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mChecking additional dependencies: ['numpy']\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFound Extra Dependecies: ['numpy']\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mInstalling Dependencies in Progress!!!\u001b[0m\n",
      "\u001b[32m2024-12-07 14:35:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1minstall additional dependencies ['numpy'] using pip\u001b[0m\n",
      "\u001b[32m2024-12-07 14:36:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mdependencies successfully installed!!\u001b[0m\n",
      "\u001b[32m2024-12-07 14:36:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mInstallation Successfully Completed!!\u001b[0m\n",
      "\u001b[32m2024-12-07 14:36:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCode Execution Result: \n",
      "Dot Product:\n",
      "[[ 58  64]\n",
      " [139 154]]\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dot Product:\\n[[ 58  64]\\n [139 154]]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = LLMPythonCodeExecutor()\n",
    "executor.execute(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2334e7fc-ef74-4044-b6ea-59174d42eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity is a measure that calculates the cosine of the angle between two non-zero vectors in an inner product space. It is often used to measure the similarity between two vectors of an inner product space, which may be normalized as a dimensionless similarity measure. The cosine similarity is defined as:\n",
      "\n",
      "\\[ \\text{cosine\\_similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} \\]\n",
      "\n",
      "Where:\n",
      "- \\( A \\cdot B \\) is the dot product of vectors A and B.\n",
      "- \\( \\|A\\| \\) and \\( \\|B\\| \\) are the magnitudes (or Euclidean norms) of vectors A and B, respectively.\n",
      "\n",
      "Here's how you can calculate the cosine similarity between two vectors in Python using different libraries:\n",
      "\n",
      "### Using NumPy\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def cosine_similarity_np(vec1, vec2):\n",
      "    dot_product = np.dot(vec1, vec2)\n",
      "    norm_vec1 = np.linalg.norm(vec1)\n",
      "    norm_vec2 = np.linalg.norm(vec2)\n",
      "    return dot_product / (norm_vec1 * norm_vec2)\n",
      "\n",
      "# Example usage\n",
      "vec1 = np.array([1, 2, 3])\n",
      "vec2 = np.array([4, 5, 6])\n",
      "similarity = cosine_similarity_np(vec1, vec2)\n",
      "print(\"Cosine Similarity using NumPy:\", similarity)\n",
      "```\n",
      "\n",
      "### Using Scikit-learn\n",
      "\n",
      "Scikit-learn provides a convenient function to calculate cosine similarity.\n",
      "\n",
      "```python\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "\n",
      "# Example usage\n",
      "vec1 = np.array([[1, 2, 3]])\n",
      "vec2 = np.array([[4, 5, 6]])\n",
      "similarity = cosine_similarity(vec1, vec2)\n",
      "print(\"Cosine Similarity using Scikit-learn:\", similarity[0][0])\n",
      "```\n",
      "\n",
      "### Using SciPy\n",
      "\n",
      "SciPy also provides a function to calculate cosine similarity.\n",
      "\n",
      "```python\n",
      "from scipy.spatial.distance import cosine\n",
      "\n",
      "def cosine_similarity_scipy(vec1, vec2):\n",
      "    return 1 - cosine(vec1, vec2)\n",
      "\n",
      "# Example usage\n",
      "vec1 = np.array([1, 2, 3])\n",
      "vec2 = np.array([4, 5, 6])\n",
      "similarity = cosine_similarity_scipy(vec1, vec2)\n",
      "print(\"Cosine Similarity using SciPy:\", similarity)\n",
      "```\n",
      "\n",
      "Each of these methods will give you the cosine similarity score between the two vectors. The Scikit-learn and SciPy methods are particularly useful if you are already using these libraries in your project.\n"
     ]
    }
   ],
   "source": [
    "response2 = llm(\"how to calculate cosine similarity score between two vectors in python\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2cfc2b-4a84-4bc7-812e-c050d12f11aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-07 14:40:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLLM Generated Text: \n",
      "Cosine similarity is a measure that calculates the cosine of the angle between two non-zero vectors in an inner product space. It is often used to measure the similarity between two vectors of an inner product space, which may be normalized as a dimensionless similarity measure. The cosine similarity is defined as:\n",
      "\n",
      "\\[ \\text{cosine\\_similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} \\]\n",
      "\n",
      "Where:\n",
      "- \\( A \\cdot B \\) is the dot product of vectors A and B.\n",
      "- \\( \\|A\\| \\) and \\( \\|B\\| \\) are the magnitudes (or Euclidean norms) of vectors A and B, respectively.\n",
      "\n",
      "Here's how you can calculate the cosine similarity between two vectors in Python using different libraries:\n",
      "\n",
      "### Using NumPy\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def cosine_similarity_np(vec1, vec2):\n",
      "    dot_product = np.dot(vec1, vec2)\n",
      "    norm_vec1 = np.linalg.norm(vec1)\n",
      "    norm_vec2 = np.linalg.norm(vec2)\n",
      "    return dot_product / (norm_vec1 * norm_vec2)\n",
      "\n",
      "# Example usage\n",
      "vec1 = np.array([1, 2, 3])\n",
      "vec2 = np.array([4, 5, 6])\n",
      "similarity = cosine_similarity_np(vec1, vec2)\n",
      "print(\"Cosine Similarity using NumPy:\", similarity)\n",
      "```\n",
      "\n",
      "### Using Scikit-learn\n",
      "\n",
      "Scikit-learn provides a convenient function to calculate cosine similarity.\n",
      "\n",
      "```python\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "\n",
      "# Example usage\n",
      "vec1 = np.array([[1, 2, 3]])\n",
      "vec2 = np.array([[4, 5, 6]])\n",
      "similarity = cosine_similarity(vec1, vec2)\n",
      "print(\"Cosine Similarity using Scikit-learn:\", similarity[0][0])\n",
      "```\n",
      "\n",
      "### Using SciPy\n",
      "\n",
      "SciPy also provides a function to calculate cosine similarity.\n",
      "\n",
      "```python\n",
      "from scipy.spatial.distance import cosine\n",
      "\n",
      "def cosine_similarity_scipy(vec1, vec2):\n",
      "    return 1 - cosine(vec1, vec2)\n",
      "\n",
      "# Example usage\n",
      "vec1 = np.array([1, 2, 3])\n",
      "vec2 = np.array([4, 5, 6])\n",
      "similarity = cosine_similarity_scipy(vec1, vec2)\n",
      "print(\"Cosine Similarity using SciPy:\", similarity)\n",
      "```\n",
      "\n",
      "Each of these methods will give you the cosine similarity score between the two vectors. The Scikit-learn and SciPy methods are particularly useful if you are already using these libraries in your project.\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mSearching for Packages to install from text\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mExtracted Python Code: \n",
      "import numpy as np\n",
      "\n",
      "def cosine_similarity_np(vec1, vec2):\n",
      "    dot_product = np.dot(vec1, vec2)\n",
      "    norm_vec1 = np.linalg.norm(vec1)\n",
      "    norm_vec2 = np.linalg.norm(vec2)\n",
      "    return dot_product / (norm_vec1 * norm_vec2)\n",
      "# Example usage\n",
      "vec1 = np.array([1, 2, 3])\n",
      "vec2 = np.array([4, 5, 6])\n",
      "similarity = cosine_similarity_np(vec1, vec2)\n",
      "print(\"Cosine Similarity using NumPy:\", similarity)\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "vec1 = np.array([[1, 2, 3]])\n",
      "vec2 = np.array([[4, 5, 6]])\n",
      "similarity = cosine_similarity(vec1, vec2)\n",
      "print(\"Cosine Similarity using Scikit-learn:\", similarity[0][0])\n",
      "from scipy.spatial.distance import cosine\n",
      "def cosine_similarity_scipy(vec1, vec2):\n",
      "    return 1 - cosine(vec1, vec2)\n",
      "similarity = cosine_similarity_scipy(vec1, vec2)\n",
      "print(\"Cosine Similarity using SciPy:\", similarity)\n",
      "\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mPython Code Dependencies: \n",
      "[{'module': 'numpy', 'name': 'numpy', 'alias': 'np'}, {'module': 'sklearn', 'name': 'cosine_similarity', 'alias': 'cosine_similarity'}, {'module': 'scipy', 'name': 'cosine', 'alias': 'cosine'}]\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCheck if packages are installed\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mChecking additional dependencies: ['numpy', 'sklearn', 'scipy']\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFound Uninstalled dependencies: ['scipy', 'sklearn']\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFound Extra Dependecies: ['scipy', 'sklearn']\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mInstalling Dependencies in Progress!!!\u001b[0m\n",
      "\u001b[32m2024-12-07 14:40:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1minstall additional dependencies ['scipy', 'sklearn'] using pip\u001b[0m\n",
      "\u001b[32m2024-12-07 14:43:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mdependencies successfully installed!!\u001b[0m\n",
      "\u001b[32m2024-12-07 14:43:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mInstallation Successfully Completed!!\u001b[0m\n",
      "\u001b[32m2024-12-07 14:43:16\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[31m\u001b[1mError Occured During Code Execution: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\agents\\code_executor\\notebook\\..\\llm_pyexecutor\\local_executor.py\", line 157, in execute\n",
      "    code_result = self._code_executor.execute_code(\n",
      "  File \"D:\\agents\\code_executor\\notebook\\..\\llm_pyexecutor\\code\\executor.py\", line 82, in execute_code\n",
      "    result = subprocess.run(\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 524, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command '['local_executor\\\\.venv\\\\Scripts\\\\python.exe', '-c', \"import numpy as np\\ndef cosine_similarity_np(vec1, vec2):\\n    dot_product = np.dot(vec1, vec2)\\n    norm_vec1 = np.linalg.norm(vec1)\\n    norm_vec2 = np.linalg.norm(vec2)\\n    return dot_product / (norm_vec1 * norm_vec2)\\nvec1 = np.array([1, 2, 3])\\nvec2 = np.array([4, 5, 6])\\nsimilarity = cosine_similarity_np(vec1, vec2)\\nprint('Cosine Similarity using NumPy:', similarity)\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nvec1 = np.array([[1, 2, 3]])\\nvec2 = np.array([[4, 5, 6]])\\nsimilarity = cosine_similarity(vec1, vec2)\\nprint('Cosine Similarity using Scikit-learn:', similarity[0][0])\\nfrom scipy.spatial.distance import cosine\\ndef cosine_similarity_scipy(vec1, vec2):\\n    return 1 - cosine(vec1, vec2)\\nsimilarity = cosine_similarity_scipy(vec1, vec2)\\nprint('Cosine Similarity using SciPy:', similarity)\\n\"]' returned non-zero exit status 1.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = executor.execute(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536e4dbb-d00b-440f-a7ca-9bb0459faab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the cosine similarity score between two vectors in Python using the `sklearn` library, you can use the `cosine_similarity` function from `sklearn.metrics.pairwise`. Here's a step-by-step guide on how to do it:\n",
      "\n",
      "1. **Install scikit-learn**: If you haven't already installed `scikit-learn`, you can do so using pip:\n",
      "   ```bash\n",
      "   pip install scikit-learn\n",
      "   ```\n",
      "\n",
      "2. **Import the necessary module**: Import the `cosine_similarity` function from `sklearn.metrics.pairwise`.\n",
      "\n",
      "3. **Define your vectors**: Create the vectors for which you want to calculate the cosine similarity.\n",
      "\n",
      "4. **Calculate the cosine similarity**: Use the `cosine_similarity` function to compute the similarity score.\n",
      "\n",
      "Here's a complete example:\n",
      "\n",
      "```python\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "import numpy as np\n",
      "\n",
      "# Define two vectors\n",
      "vector_a = np.array([[1, 2, 3]])\n",
      "vector_b = np.array([[4, 5, 6]])\n",
      "\n",
      "# Calculate cosine similarity\n",
      "similarity_score = cosine_similarity(vector_a, vector_b)\n",
      "\n",
      "# The result is a 2D array, so we extract the score\n",
      "cosine_sim_score = similarity_score[0][0]\n",
      "\n",
      "print(f\"Cosine Similarity Score: {cosine_sim_score}\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **Vectors**: `vector_a` and `vector_b` are defined as 2D numpy arrays. The `cosine_similarity` function expects the input vectors to be in this format.\n",
      "- **cosine_similarity**: This function computes the cosine similarity between samples in `X` and `Y`. If `Y` is not provided, it computes the similarity between samples in `X`.\n",
      "- **Result**: The result is a 2D array where each element `[i, j]` is the cosine similarity between the `i`-th vector in `X` and the `j`-th vector in `Y`. Since we are comparing two single vectors, the result is a 1x1 array, and we extract the single value using `[0][0]`.\n",
      "\n",
      "This method is efficient and leverages the optimized operations provided by `scikit-learn`.\n"
     ]
    }
   ],
   "source": [
    "response3 = llm(\"how to calculate cosine similarity score between two vectors in python using sklearn\")\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a003237e-b991-49ae-858a-9d57a67ca339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-07 14:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLLM Generated Text: \n",
      "To calculate the cosine similarity score between two vectors in Python using the `sklearn` library, you can use the `cosine_similarity` function from `sklearn.metrics.pairwise`. Here's a step-by-step guide on how to do it:\n",
      "\n",
      "1. **Install scikit-learn**: If you haven't already installed `scikit-learn`, you can do so using pip:\n",
      "   ```bash\n",
      "   pip install scikit-learn\n",
      "   ```\n",
      "\n",
      "2. **Import the necessary module**: Import the `cosine_similarity` function from `sklearn.metrics.pairwise`.\n",
      "\n",
      "3. **Define your vectors**: Create the vectors for which you want to calculate the cosine similarity.\n",
      "\n",
      "4. **Calculate the cosine similarity**: Use the `cosine_similarity` function to compute the similarity score.\n",
      "\n",
      "Here's a complete example:\n",
      "\n",
      "```python\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "import numpy as np\n",
      "\n",
      "# Define two vectors\n",
      "vector_a = np.array([[1, 2, 3]])\n",
      "vector_b = np.array([[4, 5, 6]])\n",
      "\n",
      "# Calculate cosine similarity\n",
      "similarity_score = cosine_similarity(vector_a, vector_b)\n",
      "\n",
      "# The result is a 2D array, so we extract the score\n",
      "cosine_sim_score = similarity_score[0][0]\n",
      "\n",
      "print(f\"Cosine Similarity Score: {cosine_sim_score}\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **Vectors**: `vector_a` and `vector_b` are defined as 2D numpy arrays. The `cosine_similarity` function expects the input vectors to be in this format.\n",
      "- **cosine_similarity**: This function computes the cosine similarity between samples in `X` and `Y`. If `Y` is not provided, it computes the similarity between samples in `X`.\n",
      "- **Result**: The result is a 2D array where each element `[i, j]` is the cosine similarity between the `i`-th vector in `X` and the `j`-th vector in `Y`. Since we are comparing two single vectors, the result is a 1x1 array, and we extract the single value using `[0][0]`.\n",
      "\n",
      "This method is efficient and leverages the optimized operations provided by `scikit-learn`.\u001b[0m\n",
      "\u001b[32m2024-12-07 14:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mSearching for Packages to install from text\u001b[0m\n",
      "\u001b[32m2024-12-07 14:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mExtracted Python Code: \n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "import numpy as np\n",
      "\n",
      "# Define two vectors\n",
      "vector_a = np.array([[1, 2, 3]])\n",
      "vector_b = np.array([[4, 5, 6]])\n",
      "# Calculate cosine similarity\n",
      "similarity_score = cosine_similarity(vector_a, vector_b)\n",
      "# The result is a 2D array, so we extract the score\n",
      "cosine_sim_score = similarity_score[0][0]\n",
      "print(f\"Cosine Similarity Score: {cosine_sim_score}\")\n",
      "\u001b[0m\n",
      "\u001b[32m2024-12-07 14:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mPython Code Dependencies: \n",
      "[{'module': 'sklearn', 'name': 'cosine_similarity', 'alias': 'cosine_similarity'}, {'module': 'numpy', 'name': 'numpy', 'alias': 'np'}]\u001b[0m\n",
      "\u001b[32m2024-12-07 14:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCheck if packages are installed\u001b[0m\n",
      "\u001b[32m2024-12-07 14:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mChecking additional dependencies: ['numpy', 'sklearn']\u001b[0m\n",
      "\u001b[32m2024-12-07 14:45:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCode Execution Result: \n",
      "Cosine Similarity Score: 0.9746318461970762\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = executor.execute(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4bdc593-ed5a-4e19-84df-bc689ff4ba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cosine Similarity Score: 0.9746318461970762\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56e083-eb5f-4ba9-8384-ff19a37b1a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
